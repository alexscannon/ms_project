{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm tqdm matplotlib\n",
    "\n",
    "# Cell 2: Mount Google Drive for saving models and checkpoints\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories for checkpoints\n",
    "!mkdir -p /content/drive/MyDrive/vit_pretraining/checkpoints/cifar100\n",
    "!mkdir -p /content/drive/MyDrive/vit_pretraining/checkpoints/tiny-imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Import libraries and set up device\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm  # Use notebook version for better Colab progress bars\n",
    "import math\n",
    "import time\n",
    "import requests\n",
    "import tarfile\n",
    "import shutil\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# For ViT model\n",
    "import timm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Set device - Colab typically provides a GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU Model: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Download and prepare Tiny-ImageNet dataset\n",
    "def download_and_extract_tiny_imagenet(data_dir=\"/content/drive/MyDrive/data\"):\n",
    "    \"\"\"\n",
    "    Downloads and extracts the Tiny-ImageNet dataset.\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    # URL for Tiny ImageNet\n",
    "    url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "\n",
    "    # Define the path to save the downloaded file\n",
    "    zip_path = os.path.join(data_dir, \"tiny-imagenet-200.zip\")\n",
    "    dataset_path = os.path.join(data_dir, \"tiny-imagenet-200\")\n",
    "\n",
    "    # Check if the dataset already exists\n",
    "    if os.path.exists(dataset_path):\n",
    "        print(f\"Dataset already exists at {dataset_path}\")\n",
    "        return dataset_path\n",
    "\n",
    "    # Download the dataset\n",
    "    print(f\"Downloading Tiny-ImageNet from {url}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Stream the download with progress updates\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 Kibibyte\n",
    "\n",
    "    with open(zip_path, 'wb') as f:\n",
    "        for data in tqdm(response.iter_content(block_size),\n",
    "                         total=total_size // block_size,\n",
    "                         unit='KiB', unit_scale=True):\n",
    "            f.write(data)\n",
    "\n",
    "    download_time = time.time() - start_time\n",
    "    print(f\"Download completed in {download_time:.2f} seconds\")\n",
    "\n",
    "    # Extract the dataset\n",
    "    print(f\"Extracting dataset to {data_dir}...\")\n",
    "    extract_start_time = time.time()\n",
    "\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        for member in tqdm(zip_ref.infolist(), desc='Extracting '):\n",
    "            zip_ref.extract(member, data_dir)\n",
    "\n",
    "    extract_time = time.time() - extract_start_time\n",
    "    print(f\"Extraction completed in {extract_time:.2f} seconds\")\n",
    "\n",
    "    # Clean up the zip file\n",
    "    os.remove(zip_path)\n",
    "    print(f\"Removed zip file {zip_path}\")\n",
    "\n",
    "    return dataset_path\n",
    "\n",
    "# Call the function to download and extract Tiny-ImageNet\n",
    "tiny_imagenet_path = download_and_extract_tiny_imagenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define TinyImageNet dataset class\n",
    "class TinyImageNet(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, train=True, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.classes = []\n",
    "        self.class_to_idx = {}\n",
    "        self.images = []\n",
    "        self.targets = []\n",
    "\n",
    "        # Determine dataset directories\n",
    "        if self.train:\n",
    "            self.train_dir = os.path.join(root, 'train')\n",
    "            if not os.path.isdir(self.train_dir):\n",
    "                raise RuntimeError(f'Train directory not found at {self.train_dir}')\n",
    "            self._load_train_data()\n",
    "        else:\n",
    "            self.val_dir = os.path.join(root, 'val')\n",
    "            if not os.path.isdir(self.val_dir):\n",
    "                raise RuntimeError(f'Val directory not found at {self.val_dir}')\n",
    "            self._load_val_data()\n",
    "\n",
    "    def _load_train_data(self):\n",
    "        # Scan for class directories\n",
    "        for class_dir in sorted(os.listdir(self.train_dir)):\n",
    "            class_path = os.path.join(self.train_dir, class_dir)\n",
    "            if os.path.isdir(class_path):\n",
    "                self.classes.append(class_dir)\n",
    "\n",
    "        # Create class mapping\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "\n",
    "        # Scan for images\n",
    "        for class_dir in self.classes:\n",
    "            class_idx = self.class_to_idx[class_dir]\n",
    "            class_path = os.path.join(self.train_dir, class_dir)\n",
    "\n",
    "            # Check if there's an 'images' subdirectory\n",
    "            images_dir = os.path.join(class_path, 'images')\n",
    "            if os.path.isdir(images_dir):\n",
    "                # Directory structure: root/train/class/images/*.JPEG\n",
    "                for img_file in os.listdir(images_dir):\n",
    "                    if img_file.endswith('.JPEG'):\n",
    "                        self.images.append(os.path.join(images_dir, img_file))\n",
    "                        self.targets.append(class_idx)\n",
    "            else:\n",
    "                # Directory structure: root/train/class/*.JPEG\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    if img_file.endswith('.JPEG'):\n",
    "                        self.images.append(os.path.join(class_path, img_file))\n",
    "                        self.targets.append(class_idx)\n",
    "\n",
    "    def _load_val_data(self):\n",
    "        # First try to find the val_annotations.txt file\n",
    "        val_annotations_path = os.path.join(self.val_dir, 'val_annotations.txt')\n",
    "\n",
    "        if os.path.isfile(val_annotations_path):\n",
    "            # Standard structure with val_annotations.txt\n",
    "\n",
    "            # First, get all classes from train set if available\n",
    "            train_dir = os.path.join(self.root, 'train')\n",
    "            if os.path.isdir(train_dir):\n",
    "                for class_dir in sorted(os.listdir(train_dir)):\n",
    "                    class_path = os.path.join(train_dir, class_dir)\n",
    "                    if os.path.isdir(class_path):\n",
    "                        self.classes.append(class_dir)\n",
    "\n",
    "            # If train set was not available, extract classes from val_annotations\n",
    "            if not self.classes:\n",
    "                with open(val_annotations_path, 'r') as f:\n",
    "                    class_ids = set()\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split('\\t')\n",
    "                        if len(parts) >= 2:\n",
    "                            class_ids.add(parts[1])\n",
    "                    self.classes = sorted(list(class_ids))\n",
    "\n",
    "            # Create class mapping\n",
    "            self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "\n",
    "            # Load images and targets from val_annotations.txt\n",
    "            images_dir = os.path.join(self.val_dir, 'images')\n",
    "            if not os.path.isdir(images_dir):\n",
    "                images_dir = self.val_dir\n",
    "\n",
    "            with open(val_annotations_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    if len(parts) >= 2:\n",
    "                        img_file, class_id = parts[0], parts[1]\n",
    "                        if class_id in self.class_to_idx:\n",
    "                            img_path = os.path.join(images_dir, img_file)\n",
    "                            if os.path.isfile(img_path):\n",
    "                                self.images.append(img_path)\n",
    "                                self.targets.append(self.class_to_idx[class_id])\n",
    "        else:\n",
    "            # Alternative structure: val dir contains subdirectories for classes\n",
    "            for class_dir in sorted(os.listdir(self.val_dir)):\n",
    "                class_path = os.path.join(self.val_dir, class_dir)\n",
    "                if os.path.isdir(class_path):\n",
    "                    self.classes.append(class_dir)\n",
    "\n",
    "            # Create class mapping\n",
    "            self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "\n",
    "            # Scan for images\n",
    "            for class_dir in self.classes:\n",
    "                class_idx = self.class_to_idx[class_dir]\n",
    "                class_path = os.path.join(self.val_dir, class_dir)\n",
    "\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    if img_file.endswith(('.JPEG', '.jpeg', '.jpg', '.png')):\n",
    "                        self.images.append(os.path.join(class_path, img_file))\n",
    "                        self.targets.append(class_idx)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images[index]\n",
    "        target = self.targets[index]\n",
    "\n",
    "        # Load image\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a dummy image as fallback\n",
    "            img = Image.new('RGB', (64, 64), color='gray')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this class after your TinyImageNet class definition\n",
    "class ClassRemappingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, class_mapping):\n",
    "        self.dataset = dataset\n",
    "        self.class_mapping = class_mapping\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.dataset[index]\n",
    "        # Map the original class index to the new consecutive index\n",
    "        new_target = self.class_mapping[target]\n",
    "        return img, new_target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Dataset preparation function\n",
    "def prepare_dataset(dataset_name, data_dir='/content/drive/MyDrive/data'):\n",
    "    \"\"\"\n",
    "    Prepare dataset for pretraining according to requirements:\n",
    "    - 80% of classes for pretraining\n",
    "    - 75% of each pretraining class examples\n",
    "    - 20% of classes reserved for continual learning\n",
    "    \"\"\"\n",
    "    if dataset_name == 'cifar100':\n",
    "        # Define transforms with stronger augmentation for training from scratch\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandAugment(num_ops=2, magnitude=9),  # More aggressive augmentation\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "            transforms.Resize((224, 224))  # Resize to ViT input size\n",
    "        ])\n",
    "\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "            transforms.Resize((224, 224))  # Resize to ViT input size\n",
    "        ])\n",
    "\n",
    "        # Load CIFAR-100 dataset\n",
    "        train_dataset = CIFAR100(root=data_dir, train=True, download=True, transform=train_transform)\n",
    "        test_dataset = CIFAR100(root=data_dir, train=False, download=True, transform=test_transform)\n",
    "\n",
    "        # Number of classes\n",
    "        n_classes = 100\n",
    "\n",
    "    elif dataset_name == 'tiny-imagenet':\n",
    "        # Define transforms for tiny-imagenet with stronger augmentation\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(64),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "            transforms.RandAugment(num_ops=2, magnitude=9),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            transforms.Resize((224, 224))  # Resize to ViT input size\n",
    "        ])\n",
    "\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            transforms.Resize((224, 224))  # Resize to ViT input size\n",
    "        ])\n",
    "\n",
    "        # Path to Tiny ImageNet\n",
    "        tiny_imagenet_root = os.path.join(data_dir, \"tiny-imagenet-200\")\n",
    "\n",
    "        # Load tiny-imagenet dataset\n",
    "        train_dataset = TinyImageNet(root=tiny_imagenet_root, train=True, transform=train_transform)\n",
    "        test_dataset = TinyImageNet(root=tiny_imagenet_root, train=False, transform=test_transform)\n",
    "\n",
    "        # Number of classes\n",
    "        n_classes = 200  # tiny-imagenet has 200 classes\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset {dataset_name} not supported\")\n",
    "\n",
    "    # Select 80% of classes for pretraining\n",
    "    n_pretrain_classes = int(0.8 * n_classes)\n",
    "    all_classes = list(range(n_classes))\n",
    "    random.shuffle(all_classes)\n",
    "    pretrain_classes = all_classes[:n_pretrain_classes]\n",
    "    continual_classes = all_classes[n_pretrain_classes:]\n",
    "\n",
    "    class_mapping = {cls: i for i, cls in enumerate(pretrain_classes)}\n",
    "\n",
    "\n",
    "    print(f\"Selected {len(pretrain_classes)} classes for pretraining\")\n",
    "    print(f\"Reserved {len(continual_classes)} classes for continual learning\")\n",
    "\n",
    "    # Create indices of samples belonging to pretraining classes\n",
    "    train_indices = [i for i, (_, label) in enumerate(train_dataset) if label in pretrain_classes]\n",
    "\n",
    "    # Group indices by class\n",
    "    class_indices = {}\n",
    "    for idx in train_indices:\n",
    "        _, label = train_dataset[idx]\n",
    "        if label not in class_indices:\n",
    "            class_indices[label] = []\n",
    "        class_indices[label].append(idx)\n",
    "\n",
    "    # Select 75% of samples for each pretraining class\n",
    "    pretrain_indices = []\n",
    "    for label, indices in class_indices.items():\n",
    "        n_samples = len(indices)\n",
    "        n_pretrain_samples = int(0.75 * n_samples)\n",
    "        pretrain_indices.extend(indices[:n_pretrain_samples])\n",
    "\n",
    "    # Create a subset dataset for pretraining\n",
    "    pretrain_subset = Subset(train_dataset, pretrain_indices)\n",
    "\n",
    "    # Wrap the subset with the class remapping dataset\n",
    "    pretrain_dataset = ClassRemappingDataset(pretrain_subset, class_mapping)\n",
    "\n",
    "    # Create train-val split (80-20) from the pretrain dataset\n",
    "    n_pretrain = len(pretrain_dataset)\n",
    "    n_val = int(0.2 * n_pretrain)\n",
    "    n_train = n_pretrain - n_val\n",
    "\n",
    "    pretrain_train_dataset, pretrain_val_dataset = random_split(\n",
    "        pretrain_dataset, [n_train, n_val]\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    # Adjust batch size based on available GPU memory - smaller for Colab\n",
    "    batch_size = 32  # Reduced from 64 for Colab's GPU memory constraints\n",
    "\n",
    "    pretrain_loader = DataLoader(\n",
    "        pretrain_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,  # Reduced for Colab\n",
    "        pin_memory=True  # Faster data transfer to GPU\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        pretrain_val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,  # Reduced for Colab\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    full_test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,  # Reduced for Colab\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    print(f\"Pretraining on {len(pretrain_train_dataset)} samples\")\n",
    "    print(f\"Validation on {len(pretrain_val_dataset)} samples\")\n",
    "    print(f\"Full test set has {len(test_dataset)} samples\")\n",
    "\n",
    "    # Store the class information for later use\n",
    "    class_info = {\n",
    "        'n_classes': n_classes,\n",
    "        'pretrain_classes': pretrain_classes,\n",
    "        'continual_classes': continual_classes\n",
    "    }\n",
    "\n",
    "    return pretrain_loader, val_loader, full_test_loader, class_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Model creation and learning rate scheduler\n",
    "def create_vit_model_from_scratch(num_classes):\n",
    "    \"\"\"\n",
    "    Create a ViT model from scratch (without pre-trained weights)\n",
    "    \"\"\"\n",
    "    # Create ViT model with random initialization (pretrained=False)\n",
    "    model = timm.create_model('vit_small_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "\n",
    "    # Better initialization for Transformers\n",
    "    def _init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.ones_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    model.apply(_init_weights)\n",
    "    return model\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "class WarmupCosineScheduler:\n",
    "    def __init__(self, optimizer, warmup_epochs, max_epochs, warmup_start_lr=1e-6, eta_min=1e-6):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.max_epochs = max_epochs\n",
    "        self.warmup_start_lr = warmup_start_lr\n",
    "        self.eta_min = eta_min\n",
    "\n",
    "        # Get base lr\n",
    "        self.base_lr = []\n",
    "        for group in optimizer.param_groups:\n",
    "            self.base_lr.append(group['lr'])\n",
    "\n",
    "    def step(self, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            # Linear warmup\n",
    "            lr_mult = epoch / self.warmup_epochs\n",
    "            for i, group in enumerate(self.optimizer.param_groups):\n",
    "                group['lr'] = self.warmup_start_lr + lr_mult * (self.base_lr[i] - self.warmup_start_lr)\n",
    "        else:\n",
    "            # Cosine annealing\n",
    "            for i, group in enumerate(self.optimizer.param_groups):\n",
    "                progress = (epoch - self.warmup_epochs) / (self.max_epochs - self.warmup_epochs)\n",
    "                cosine_decay = 0.5 * (1 + math.cos(math.pi * progress))\n",
    "                group['lr'] = self.eta_min + cosine_decay * (self.base_lr[i] - self.eta_min)\n",
    "\n",
    "        return [group['lr'] for group in self.optimizer.param_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Training function\n",
    "def train_model_from_scratch(model, train_loader, val_loader, class_info, dataset_name,\n",
    "                             num_epochs=50):  # Reduced epochs for Colab\n",
    "    \"\"\"\n",
    "    Train the ViT model from scratch with proper hyperparameters\n",
    "    \"\"\"\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    # Higher learning rate for training from scratch\n",
    "    # Weight decay is important for regularization when training from scratch\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.05, betas=(0.9, 0.999))\n",
    "\n",
    "    # Learning rate scheduler with warmup\n",
    "    warmup_epochs = 10\n",
    "    scheduler = WarmupCosineScheduler(\n",
    "        optimizer,\n",
    "        warmup_epochs=warmup_epochs,\n",
    "        max_epochs=num_epochs,\n",
    "        warmup_start_lr=1e-6,\n",
    "        eta_min=1e-6\n",
    "    )\n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Training and validation history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "\n",
    "    # Best model tracking\n",
    "    best_val_acc = 0.0\n",
    "    patience = 10  # Early stopping patience\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Checkpoint directory on Google Drive\n",
    "    checkpoint_dir = f\"/content/drive/MyDrive/vit_pretraining/checkpoints/{dataset_name}\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # Update learning rate\n",
    "        current_lr = scheduler.step(epoch)\n",
    "        history['lr'].append(current_lr[0])  # Log learning rate\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track statistics\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += targets.size(0)\n",
    "            train_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': train_loss / (batch_idx + 1),\n",
    "                'acc': 100. * train_correct / train_total,\n",
    "                'lr': current_lr[0]\n",
    "            })\n",
    "\n",
    "            # Free up GPU memory\n",
    "            del inputs, targets, outputs, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Calculate average training metrics\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "            for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                # Track statistics\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({\n",
    "                    'loss': val_loss / (batch_idx + 1),\n",
    "                    'acc': 100. * val_correct / val_total\n",
    "                })\n",
    "\n",
    "                # Free up GPU memory\n",
    "                del inputs, targets, outputs, loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # Calculate average validation metrics\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "\n",
    "        # Calculate epoch time\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% - \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}% - \"\n",
    "              f\"LR: {current_lr[0]:.6f} - \"\n",
    "              f\"Time: {epoch_time:.1f}s\")\n",
    "\n",
    "        # Save to history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        # Plot training progress\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:  # Every 5 epochs\n",
    "            plot_training_progress(history, dataset_name)\n",
    "\n",
    "        # Save best model and check early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "            print(f\"New best validation accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "            # Save the best model\n",
    "            save_model(model, optimizer, epoch, history, class_info, dataset_name,\n",
    "                      checkpoint_dir=checkpoint_dir, is_best=True)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Validation accuracy did not improve. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Save checkpoint every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            save_model(model, optimizer, epoch, history, class_info, dataset_name,\n",
    "                      checkpoint_dir=checkpoint_dir, is_best=False,\n",
    "                      checkpoint_name=f\"checkpoint_epoch_{epoch+1}\")\n",
    "\n",
    "    # Save final model\n",
    "    save_model(model, optimizer, epoch, history, class_info, dataset_name,\n",
    "              checkpoint_dir=checkpoint_dir, is_best=False)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Functions for saving, evaluating, and loading models\n",
    "def save_model(model, optimizer, epoch, history, class_info, dataset_name,\n",
    "              checkpoint_dir=None, is_best=False, checkpoint_name=None):\n",
    "    \"\"\"\n",
    "    Save model checkpoint\n",
    "    \"\"\"\n",
    "    if checkpoint_dir is None:\n",
    "        checkpoint_dir = f\"/content/drive/MyDrive/vit_pretraining/checkpoints/{dataset_name}\"\n",
    "\n",
    "    if checkpoint_name:\n",
    "        model_type = checkpoint_name\n",
    "    else:\n",
    "        model_type = 'best' if is_best else 'final'\n",
    "\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"vit_{model_type}_checkpoint.pth\")\n",
    "\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'history': history,\n",
    "        'class_info': class_info\n",
    "    }\n",
    "\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Saved {model_type} model checkpoint to {checkpoint_path}\")\n",
    "\n",
    "def evaluate_model(model, test_loader, class_info):\n",
    "    \"\"\"\n",
    "    Evaluate model on the full test set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    # Class-wise accuracy\n",
    "    class_correct = {}\n",
    "    class_total = {}\n",
    "\n",
    "    # Initialize counters for each class\n",
    "    for cls in range(class_info['n_classes']):\n",
    "        class_correct[cls] = 0\n",
    "        class_total[cls] = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    inverse_mapping = {i: cls for i, cls in enumerate(class_info['pretrain_classes'])}\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, desc=\"Evaluating\")\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Track overall statistics\n",
    "            _, predicted = outputs.max(1)\n",
    "            predicted = torch.tensor([inverse_mapping[p.item()] for p in predicted], device=device)\n",
    "            test_total += targets.size(0)\n",
    "            test_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # Track class-wise statistics\n",
    "            for i in range(len(class_info['pretrain_classes'])):\n",
    "                cls = inverse_mapping[i]  # Get original class index\n",
    "                cls_idx = (targets == i)\n",
    "                class_total[cls] += cls_idx.sum().item()\n",
    "                class_correct[cls] += (predicted.eq(targets) & cls_idx).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'acc': 100. * test_correct / test_total\n",
    "            })\n",
    "\n",
    "            # Free up GPU memory\n",
    "            del inputs, targets, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Calculate average test metrics\n",
    "    test_acc = 100. * test_correct / test_total\n",
    "\n",
    "    print(f\"Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    # Calculate accuracy for pretrain and continual classes\n",
    "    pretrain_correct = sum(class_correct[cls] for cls in class_info['pretrain_classes'])\n",
    "    pretrain_total = sum(class_total[cls] for cls in class_info['pretrain_classes'])\n",
    "    pretrain_acc = 100. * pretrain_correct / pretrain_total if pretrain_total > 0 else 0\n",
    "\n",
    "    continual_correct = sum(class_correct[cls] for cls in class_info['continual_classes'])\n",
    "    continual_total = sum(class_total[cls] for cls in class_info['continual_classes'])\n",
    "    continual_acc = 100. * continual_correct / continual_total if continual_total > 0 else 0\n",
    "\n",
    "    print(f\"Pretrain Classes Acc: {pretrain_acc:.2f}%\")\n",
    "    print(f\"Continual Classes Acc: {continual_acc:.2f}%\")\n",
    "\n",
    "    return test_acc, {\n",
    "        'pretrain_acc': pretrain_acc,\n",
    "        'continual_acc': continual_acc,\n",
    "        'class_acc': {cls: 100. * class_correct[cls] / class_total[cls] if class_total[cls] > 0 else 0\n",
    "                     for cls in range(class_info['n_classes'])}\n",
    "    }\n",
    "\n",
    "def load_pretrained_model(dataset_name, model_type='best', checkpoint_dir=None):\n",
    "    \"\"\"\n",
    "    Load a pretrained ViT model\n",
    "    \"\"\"\n",
    "    if checkpoint_dir is None:\n",
    "        checkpoint_dir = f\"/content/drive/MyDrive/vit_pretraining/checkpoints/{dataset_name}\"\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"vit_{model_type}_checkpoint.pth\")\n",
    "\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}\")\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    class_info = checkpoint['class_info']\n",
    "    model = create_vit_model_from_scratch(num_classes=len(class_info['pretrain_classes']))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(f\"Loaded {model_type} {dataset_name} ViT model from {checkpoint_path}\")\n",
    "    print(f\"Model was trained for {checkpoint['epoch'] + 1} epochs\")\n",
    "\n",
    "    return model, class_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Visualization functions\n",
    "def plot_training_progress(history, dataset_name):\n",
    "    \"\"\"\n",
    "    Plot training progress during training\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'{dataset_name} Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Acc')\n",
    "    plt.plot(history['val_acc'], label='Val Acc')\n",
    "    plt.title(f'{dataset_name} Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot learning rate\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history['lr'])\n",
    "    plt.title(f'{dataset_name} Learning Rate')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_history(history, dataset_name):\n",
    "    \"\"\"\n",
    "    Plot complete training history after training\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'{dataset_name} Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Acc')\n",
    "    plt.plot(history['val_acc'], label='Val Acc')\n",
    "    plt.title(f'{dataset_name} Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot learning rate\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history['lr'])\n",
    "    plt.title(f'{dataset_name} Learning Rate')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    # Save the figure to Google Drive\n",
    "    save_path = f\"/content/drive/MyDrive/vit_pretraining/{dataset_name}_training_history.png\"\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Saved training history plot to {save_path}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Main training function\n",
    "def train_cifar100():\n",
    "    \"\"\"\n",
    "    Train ViT on CIFAR-100 from scratch\n",
    "    \"\"\"\n",
    "    # Set seed for reproducibility\n",
    "    set_seed(42)\n",
    "\n",
    "    print(\"=== Pretraining ViT on CIFAR-100 from scratch ===\")\n",
    "    cifar_train_loader, cifar_val_loader, cifar_test_loader, cifar_class_info = prepare_dataset('cifar100')\n",
    "\n",
    "    cifar_model = create_vit_model_from_scratch(num_classes=len(cifar_class_info['pretrain_classes']))\n",
    "    cifar_model, cifar_history = train_model_from_scratch(\n",
    "        cifar_model, cifar_train_loader, cifar_val_loader, cifar_class_info, 'cifar100'\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Evaluating CIFAR-100 ViT on Full Test Set ===\")\n",
    "    evaluate_model(cifar_model, cifar_test_loader, cifar_class_info)\n",
    "\n",
    "    # Plot final training history\n",
    "    plot_training_history(cifar_history, 'cifar100')\n",
    "\n",
    "    print(\"\\nCIFAR-100 pretraining complete! Model saved to Google Drive.\")\n",
    "    return cifar_model, cifar_history, cifar_class_info\n",
    "\n",
    "def train_tiny_imagenet():\n",
    "    \"\"\"\n",
    "    Train ViT on Tiny-ImageNet from scratch\n",
    "    \"\"\"\n",
    "    # Set seed for reproducibility\n",
    "    set_seed(42)\n",
    "\n",
    "    print(\"\\n=== Pretraining ViT on Tiny-ImageNet from scratch ===\")\n",
    "    tiny_train_loader, tiny_val_loader, tiny_test_loader, tiny_class_info = prepare_dataset('tiny-imagenet')\n",
    "\n",
    "    tiny_model = create_vit_model_from_scratch(num_classes=len(tiny_class_info['pretrain_classes']))\n",
    "    tiny_model, tiny_history = train_model_from_scratch(\n",
    "        tiny_model, tiny_train_loader, tiny_val_loader, tiny_class_info, 'tiny-imagenet'\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Evaluating Tiny-ImageNet ViT on Full Test Set ===\")\n",
    "    evaluate_model(tiny_model, tiny_test_loader, tiny_class_info)\n",
    "\n",
    "    # Plot final training history\n",
    "    plot_training_history(tiny_history, 'tiny-imagenet')\n",
    "\n",
    "    print(\"\\nTiny-ImageNet pretraining complete! Model saved to Google Drive.\")\n",
    "    return tiny_model, tiny_history, tiny_class_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Evaluation function\n",
    "def check_models_on_full_dataset():\n",
    "    \"\"\"\n",
    "    Check the pre-trained models on the full dataset\n",
    "    \"\"\"\n",
    "    print(\"=== Checking Pre-trained Models on Full Datasets ===\")\n",
    "\n",
    "    # Check if pretrained models exist\n",
    "    cifar_checkpoint_path = \"/content/drive/MyDrive/vit_pretraining/checkpoints/cifar100/vit_best_checkpoint.pth\"\n",
    "    tiny_checkpoint_path = \"/content/drive/MyDrive/vit_pretraining/checkpoints/tiny-imagenet/vit_best_checkpoint.pth\"\n",
    "\n",
    "    models_found = True\n",
    "\n",
    "    if not os.path.exists(cifar_checkpoint_path):\n",
    "        print(f\"CIFAR-100 model not found at {cifar_checkpoint_path}\")\n",
    "        models_found = False\n",
    "\n",
    "    if not os.path.exists(tiny_checkpoint_path):\n",
    "        print(f\"Tiny-ImageNet model not found at {tiny_checkpoint_path}\")\n",
    "        models_found = False\n",
    "\n",
    "    if not models_found:\n",
    "        print(\"Some pretrained models not found. Please run the pretraining first.\")\n",
    "        return\n",
    "\n",
    "    # Load the models\n",
    "    cifar_model, cifar_class_info = load_pretrained_model('cifar100')\n",
    "    tiny_model, tiny_class_info = load_pretrained_model('tiny-imagenet')\n",
    "\n",
    "    # Load the datasets\n",
    "    _, _, cifar_test_loader, _ = prepare_dataset('cifar100')\n",
    "    _, _, tiny_test_loader, _ = prepare_dataset('tiny-imagenet')\n",
    "\n",
    "    # Evaluate on full test set\n",
    "    print(\"\\n=== Evaluating CIFAR-100 ViT on Full Test Set ===\")\n",
    "    cifar_results = evaluate_model(cifar_model, cifar_test_loader, cifar_class_info)\n",
    "\n",
    "    print(\"\\n=== Evaluating Tiny-ImageNet ViT on Full Test Set ===\")\n",
    "    tiny_results = evaluate_model(tiny_model, tiny_test_loader, tiny_class_info)\n",
    "\n",
    "    # Analyze performance on pretrain vs continual classes\n",
    "    print(\"\\n=== Performance Analysis ===\")\n",
    "    print(\"CIFAR-100:\")\n",
    "    print(f\"  Pretrain Classes Accuracy: {cifar_results[2]['pretrain_acc']:.2f}%\")\n",
    "    print(f\"  Continual Classes Accuracy: {cifar_results[2]['continual_acc']:.2f}%\")\n",
    "\n",
    "    print(\"\\nTiny-ImageNet:\")\n",
    "    print(f\"  Pretrain Classes Accuracy: {tiny_results[2]['pretrain_acc']:.2f}%\")\n",
    "    print(f\"  Continual Classes Accuracy: {tiny_results[2]['continual_acc']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Run the training for CIFAR-100\n",
    "# Uncomment the line below to run the CIFAR-100 training\n",
    "# cifar_model, cifar_history, cifar_class_info = train_cifar100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Run the training for Tiny-ImageNet\n",
    "# Uncomment the line below to run the Tiny-ImageNet training\n",
    "# tiny_model, tiny_history, tiny_class_info = train_tiny_imagenet()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omccood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
