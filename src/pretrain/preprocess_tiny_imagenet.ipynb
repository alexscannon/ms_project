{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Import necessary libraries\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Configuration\n",
    "TINY_IMAGENET_URL = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip' # Or use .tar.gz if preferred\n",
    "\n",
    "DRIVE_MOUNT_POINT = '/Users/alexc/Education/OMSCS/Masters_Project/msproject_repo/data' # Optional: Google Drive mount point\n",
    "DATA_DIR = DRIVE_MOUNT_POINT + '/tiny-imagenet-200'\n",
    "SAVE_DIR = DATA_DIR + '/preprocessed_tinyimagenet'\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Data split ratios\n",
    "IND_CLASS_RATIO = 0.80  # 80% of classes for In-Distribution\n",
    "PRETRAIN_EXAMPLE_RATIO = 0.75  # 75% of examples from ID classes for actual pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Setup\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(RANDOM_SEED)\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be saved in: /Users/alexc/Education/OMSCS/Masters_Project/msproject_repo/data/tiny-imagenet-200\n",
      "Preprocessed data will be saved in: /Users/alexc/Education/OMSCS/Masters_Project/msproject_repo/data/tiny-imagenet-200/preprocessed_tinyimagenet\n",
      "Downloading Tiny-ImageNet dataset...\n",
      "Downloading: 100.00%\n",
      "Download complete!\n",
      "Extracting dataset...\n",
      "Extraction complete!\n",
      "Number of classes in training set: 200\n",
      "Example classes: ['n02795169', 'n02769748', 'n07920052', 'n02917067', 'n01629819']\n",
      "Number of images in n02795169: 500\n",
      "Example image paths: ['n02795169_369.JPEG', 'n02795169_386.JPEG', 'n02795169_105.JPEG']\n",
      "Dataset structure validation complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Download + extract Tiny Imagenet\n",
    "# Create a directory for our dataset\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(f\"Data will be saved in: {DATA_DIR}\")\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f\"Preprocessed data will be saved in: {SAVE_DIR}\")\n",
    "\n",
    "\n",
    "# URL for the Tiny-ImageNet dataset\n",
    "zip_path = os.path.join(DATA_DIR, 'tiny-imagenet-200.zip')\n",
    "\n",
    "# Download the dataset if it doesn't exist\n",
    "if not os.path.exists(zip_path):\n",
    "    print(\"Downloading Tiny-ImageNet dataset...\")\n",
    "\n",
    "    # Create a progress bar for download\n",
    "    def report_progress(block_num, block_size, total_size):\n",
    "        progress = float(block_num * block_size) / float(total_size) * 100.0\n",
    "        print(f\"\\rDownloading: {progress:.2f}%\", end=\"\")\n",
    "\n",
    "    # Download with progress reporting\n",
    "    urllib.request.urlretrieve(TINY_IMAGENET_URL, zip_path, reporthook=report_progress)\n",
    "    print(\"\\nDownload complete!\")\n",
    "else:\n",
    "    print(\"Dataset already downloaded.\")\n",
    "\n",
    "# Extract the dataset if not already extracted\n",
    "extract_dir = os.path.join(DATA_DIR, 'tiny-imagenet-200')\n",
    "if not os.path.exists(extract_dir):\n",
    "    print(\"Extracting dataset...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATA_DIR)\n",
    "    print(\"Extraction complete!\")\n",
    "else:\n",
    "    print(\"Dataset already extracted.\")\n",
    "\n",
    "# Basic validation to check the dataset structure\n",
    "train_dir = os.path.join(extract_dir, 'train')\n",
    "val_dir = os.path.join(extract_dir, 'test')\n",
    "\n",
    "if os.path.exists(train_dir) and os.path.exists(val_dir):\n",
    "    # Count the number of classes in training set\n",
    "    train_classes = os.listdir(train_dir)\n",
    "    print(f\"Number of classes in training set: {len(train_classes)}\")\n",
    "\n",
    "    # Check a few example classes\n",
    "    print(f\"Example classes: {train_classes[:5]}\")\n",
    "\n",
    "    # Check the structure of one class\n",
    "    example_class = train_classes[0]\n",
    "    example_class_dir = os.path.join(train_dir, example_class)\n",
    "    example_images_dir = os.path.join(example_class_dir, 'images')\n",
    "    example_images = os.listdir(example_images_dir)\n",
    "\n",
    "    print(f\"Number of images in {example_class}: {len(example_images)}\")\n",
    "    print(f\"Example image paths: {example_images[:3]}\")\n",
    "    print(\"Dataset structure validation complete!\")\n",
    "else:\n",
    "    print(\"Dataset structure seems incorrect. Please check the extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in training set (all_wnids_ordered): 200\n",
      "Scanning Tiny ImageNet training directory...\n",
      "Found 100000 training images from 200 classes.\n",
      "\n",
      "Total classes: 200\n",
      "In-distribution (ID) classes selected (original indices): 160\n",
      "Out-of-distribution (OOD) classes selected (original indices): 40\n"
     ]
    }
   ],
   "source": [
    "# ====================== 1. Split classes into In-Distribution (ID) and Out-of-Distribution (OOD) ======================\n",
    "\n",
    "\"\"\"\n",
    "Gathers details of the Tiny ImageNet training set.\n",
    "Returns:\n",
    "    - sample_details: List of dicts, each {'path': str, 'original_label_idx': int, 'original_example_dataset_idx': int, 'wnid': str}\n",
    "    - wnid_to_idx: Dict mapping WNID to original integer label (0-199)\n",
    "    - idx_to_wnid: Dict mapping original integer label to WNID\n",
    "    - all_wnids_ordered: List of WNIDs, order defines the 0-199 mapping\n",
    "\"\"\"\n",
    "tiny_imagenet_dir = os.path.join(DATA_DIR, 'tiny-imagenet-200')\n",
    "train_dir = os.path.join(tiny_imagenet_dir, 'train')\n",
    "wnids_file = os.path.join(tiny_imagenet_dir, 'wnids.txt')\n",
    "\n",
    "with open(wnids_file, 'r') as f:\n",
    "    all_wnids_ordered = [line.strip() for line in f]\n",
    "\n",
    "print(f\"Number of classes in training set (all_wnids_ordered): {len(all_wnids_ordered)}\")\n",
    "\n",
    "wnid_to_idx = {wnid: i for i, wnid in enumerate(all_wnids_ordered)}\n",
    "idx_to_wnid = {i: wnid for wnid, i in wnid_to_idx.items()}\n",
    "\n",
    "sample_details = []\n",
    "current_original_example_dataset_idx = 0\n",
    "\n",
    "print(\"Scanning Tiny ImageNet training directory...\")\n",
    "for wnid in os.listdir(train_dir):\n",
    "    if wnid not in wnid_to_idx:\n",
    "        print(f\"Warning: WNID '{wnid}' not found in wnids.txt. Skipping...\")\n",
    "        continue # Skip non-class folders like .DS_Store\n",
    "\n",
    "    wnid_idx = wnid_to_idx[wnid]\n",
    "    class_image_dir = os.path.join(train_dir, wnid, 'images')\n",
    "\n",
    "    # Check if 'images' subdirectory exists, if not, check current wnid directory\n",
    "    if not os.path.isdir(class_image_dir):\n",
    "          img_files_dir = os.path.join(train_dir, wnid)\n",
    "    else:\n",
    "        img_files_dir = class_image_dir\n",
    "\n",
    "    for img_name in os.listdir(img_files_dir):\n",
    "        if img_name.lower().endswith(('.jpeg', '.jpg', '.png')):\n",
    "            img_path = os.path.join(img_files_dir, img_name)\n",
    "            sample_details.append({\n",
    "                'path': img_path,\n",
    "                'wnid_idx': wnid_idx, # index in the parent directory\n",
    "                'original_example_dataset_idx': current_original_example_dataset_idx, # index as if all the examples from every class were in one folder\n",
    "                'wnid': wnid\n",
    "            })\n",
    "            current_original_example_dataset_idx += 1\n",
    "\n",
    "if not sample_details:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No images found. Please check the structure of {train_dir}. \"\n",
    "        f\"Expected structure: {train_dir}/<wnid>/images/<image_file.JPEG> or {train_dir}/<wnid>/<image_file.JPEG>\"\n",
    "    )\n",
    "\n",
    "print(f\"Found {len(sample_details)} training images from {len(all_wnids_ordered)} classes.\")\n",
    "\n",
    "if not os.path.exists(tiny_imagenet_dir):\n",
    "    print(f\"Error: Tiny ImageNet directory not found at '{tiny_imagenet_dir}'.\")\n",
    "    print(f\"Please download and extract Tiny ImageNet to the {DATA_DIR}\")\n",
    "    raise FileNotFoundError\n",
    "\n",
    "num_total_original_classes = len(all_wnids_ordered) # Should be 200\n",
    "\n",
    "logging.info(f\"\\nSplitting classes into In-Distribution (ID) and Out-of-Distribution (OOD)...\")\n",
    "\n",
    "all_original_class_indices = list(range(num_total_original_classes)) # [0, 1, ..., 199]\n",
    "random.shuffle(all_original_class_indices)\n",
    "\n",
    "num_of_ind_classes = int(IND_CLASS_RATIO * num_total_original_classes) # ex., 122\n",
    "\n",
    "pretrain_classes_original_idxs = sorted(all_original_class_indices[:num_of_ind_classes])\n",
    "ood_classes_original_idxs = sorted(all_original_class_indices[num_of_ind_classes:])\n",
    "\n",
    "print(f\"\\nTotal classes: {num_total_original_classes}\")\n",
    "print(f\"In-distribution (ID) classes selected (original indices): {len(pretrain_classes_original_idxs)}\")\n",
    "print(f\"Out-of-distribution (OOD) classes selected (original indices): {len(ood_classes_original_idxs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting samples for ID classes:\n",
      "Total samples for ViT pretraining (75% of ID): 60000\n",
      "Total ID samples left out from pretraining (25% of ID): 20000\n",
      "\n",
      "Preprocessing complete. Data information saved to: /Users/alexc/Education/OMSCS/Masters_Project/msproject_repo/data/tiny-imagenet-200/preprocessed_tinyimagenet/tiny_imagenet_data_info.pth\n",
      "Class_info (for OOD experiments) saved to: /Users/alexc/Education/OMSCS/Masters_Project/msproject_repo/data/tiny-imagenet-200/preprocessed_tinyimagenet/class_info.pth\n"
     ]
    }
   ],
   "source": [
    "# ====================== 2. Create mapping for ID classes to new contiguous labels [0, num_of_ind_classes-1] ======================\n",
    "ind_wnid_idx_mapping_from_original = {\n",
    "    original_wnid_idx: new_idx for new_idx, original_wnid_idx in enumerate(pretrain_classes_original_idxs)\n",
    "}\n",
    "\n",
    "# 3. Group samples by their original class\n",
    "samples_by_original_class = defaultdict(list)\n",
    "for sample in sample_details:\n",
    "    samples_by_original_class[sample['wnid_idx']].append(sample)\n",
    "\n",
    "pretrained_ind_indices = []      # List of original_example_dataset_idx for ViT training (75% of ID)\n",
    "pretrained_left_out_indices = [] # List of original_example_dataset_idx for ID data not used in ViT training (25% of ID)\n",
    "\n",
    "print(\"\\nSplitting samples for ID classes:\")\n",
    "for wnid_idx in pretrain_classes_original_idxs:\n",
    "    class_samples = samples_by_original_class[wnid_idx]\n",
    "    random.shuffle(class_samples) # Shuffle samples within the class\n",
    "\n",
    "    num_samples_in_class = len(class_samples)\n",
    "    num_for_pretrain = int(PRETRAIN_EXAMPLE_RATIO * num_samples_in_class)\n",
    "\n",
    "    # Ensure at least one sample for pretraining if class is not empty\n",
    "    if num_samples_in_class > 0 and num_for_pretrain == 0:\n",
    "        num_for_pretrain = 1\n",
    "\n",
    "    for i, sample in enumerate(class_samples):\n",
    "        if i < num_for_pretrain:\n",
    "            pretrained_ind_indices.append(sample['original_example_dataset_idx'])\n",
    "        else:\n",
    "            pretrained_left_out_indices.append(sample['original_example_dataset_idx'])\n",
    "\n",
    "pretrained_ind_indices.sort()\n",
    "pretrained_left_out_indices.sort()\n",
    "\n",
    "print(f\"Total samples for ViT pretraining (75% of ID): {len(pretrained_ind_indices)}\")\n",
    "print(f\"Total ID samples left out from pretraining (25% of ID): {len(pretrained_left_out_indices)}\")\n",
    "\n",
    "# Store class information\n",
    "class_info = {\n",
    "    'num_of_classes': num_total_original_classes,\n",
    "    'pretrain_classes': pretrain_classes_original_idxs, # List of original class indices (0-199) for ID\n",
    "    'left_out_classes': ood_classes_original_idxs,   # List of original class indices (0-199) for OOD\n",
    "    'pretrained_ind_indices': pretrained_ind_indices,\n",
    "    'left_out_ind_indices': pretrained_left_out_indices,\n",
    "    'pretrain_class_mapping': ind_wnid_idx_mapping_from_original, # Maps original ID class_idx -> new contiguous idx\n",
    "    'wnid_to_idx': wnid_to_idx, # wnid -> original_idx (0-199)\n",
    "    'idx_to_wnid': idx_to_wnid, # original_idx (0-199) -> wnid\n",
    "    'all_wnids_ordered': all_wnids_ordered # Defines the 0-199 mapping\n",
    "}\n",
    "\n",
    "# Save all image paths and their original labels for easy access in the training script\n",
    "# This avoids re-scanning the directory in the training script.\n",
    "all_training_image_paths = [s['path'] for s in sample_details]\n",
    "all_training_original_labels = [s['wnid_idx'] for s in sample_details]\n",
    "\n",
    "data_to_save = {\n",
    "    'class_info': class_info,\n",
    "    'all_training_image_paths': all_training_image_paths,\n",
    "    'all_training_original_labels': all_training_original_labels\n",
    "}\n",
    "\n",
    "save_file = os.path.join(SAVE_DIR, 'tiny_imagenet_data_info.pth')\n",
    "torch.save(data_to_save, save_file)\n",
    "print(f\"\\nPreprocessing complete. Data information saved to: {save_file}\")\n",
    "\n",
    "# For convenience, also save just the class_info as requested by user for OOD experiments\n",
    "class_info_only_file = os.path.join(SAVE_DIR, 'class_info.pth')\n",
    "torch.save(class_info, class_info_only_file)\n",
    "print(f\"Class_info (for OOD experiments) saved to: {class_info_only_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omccood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
