{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Connect to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install necessary libraries\n",
    "!pip install torch torchvision torchaudio matplotlib numpy einops scikit-learn timm tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Import necessary libraries\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import zipfile\n",
    "from urllib import request\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Configuration\n",
    "# --- Configuration ---\n",
    "TINY_IMAGENET_URL = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip' # Or use .tar.gz if preferred\n",
    "DRIVE_MOUNT_POINT = '/content/drive/MyDrive/' # Optional: Google Drive mount point\n",
    "DATA_DIR = DRIVE_MOUNT_POINT + 'data/tiny-imagenet-200-1'\n",
    "SAVE_DIR = DRIVE_MOUNT_POINT + 'data/preprocessed_tinyimagenet'\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Data split ratios\n",
    "IND_CLASS_RATIO = 0.80  # 80% of classes for In-Distribution\n",
    "PRETRAIN_EXAMPLE_RATIO = 0.75  # 75% of examples from ID classes for actual pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Setup\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(RANDOM_SEED)\n",
    "logging.info(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 6: Download + extract Tiny Imagenet\n",
    "# Create a directory for our dataset\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "logging.info(f\"Data will be saved in: {DATA_DIR}\")\n",
    "\n",
    "\n",
    "# URL for the Tiny-ImageNet dataset\n",
    "zip_path = os.path.join(DATA_DIR, 'tiny-imagenet-200.zip')\n",
    "\n",
    "# Download the dataset if it doesn't exist\n",
    "if not os.path.exists(zip_path):\n",
    "    logging.info(\"Downloading Tiny-ImageNet dataset...\")\n",
    "\n",
    "    # Create a progress bar for download\n",
    "    def report_progress(block_num, block_size, total_size):\n",
    "        progress = float(block_num * block_size) / float(total_size) * 100.0\n",
    "        logging.info(f\"\\rDownloading: {progress:.2f}%\", end=\"\")\n",
    "\n",
    "    # Download with progress reporting\n",
    "    urllib.request.urlretrieve(TINY_IMAGENET_URL, zip_path, reporthook=report_progress)\n",
    "    logging.info(\"\\nDownload complete!\")\n",
    "else:\n",
    "    logging.info(\"Dataset already downloaded.\")\n",
    "\n",
    "# Extract the dataset if not already extracted\n",
    "extract_dir = os.path.join(DATA_DIR, 'tiny-imagenet-200')\n",
    "if not os.path.exists(extract_dir):\n",
    "    logging.info(\"Extracting dataset...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATA_DIR)\n",
    "    logging.info(\"Extraction complete!\")\n",
    "else:\n",
    "    logging.info(\"Dataset already extracted.\")\n",
    "\n",
    "# Basic validation to check the dataset structure\n",
    "train_dir = os.path.join(extract_dir, 'train')\n",
    "val_dir = os.path.join(extract_dir, 'test')\n",
    "\n",
    "if os.path.exists(train_dir) and os.path.exists(val_dir):\n",
    "    # Count the number of classes in training set\n",
    "    train_classes = os.listdir(train_dir)\n",
    "    logging.info(f\"Number of classes in training set: {len(train_classes)}\")\n",
    "\n",
    "    # Check a few example classes\n",
    "    logging.info(f\"Example classes: {train_classes[:5]}\")\n",
    "\n",
    "    # Check the structure of one class\n",
    "    example_class = train_classes[0]\n",
    "    example_class_dir = os.path.join(train_dir, example_class)\n",
    "    example_images_dir = os.path.join(example_class_dir, 'images')\n",
    "    example_images = os.listdir(example_images_dir)\n",
    "\n",
    "    logging.info(f\"Number of images in {example_class}: {len(example_images)}\")\n",
    "    logging.info(f\"Example image paths: {example_images[:3]}\")\n",
    "    logging.info(\"Dataset structure validation complete!\")\n",
    "\n",
    "else:\n",
    "    logging.info(\"Dataset structure seems incorrect. Please check the extraction.\")\n",
    "\n",
    "# Output from Colab\n",
    "# Data will be saved in: /content/drive/MyDrive/data/tiny-imagenet-200-1\n",
    "# Dataset already downloaded.\n",
    "# Dataset already extracted.\n",
    "# Number of classes in training set: 122\n",
    "# Example classes: ['n03584254', 'n02403003', 'n02056570', 'n02769748', 'n01443537']\n",
    "# Number of images in n03584254: 500\n",
    "# Example image paths: ['n03584254_251.JPEG', 'n03584254_348.JPEG', 'n03584254_465.JPEG']\n",
    "# Dataset structure validation complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Get Tiny ImageNet train data details\n",
    "def get_tiny_imagenet_train_data_details(dataset_path):\n",
    "    \"\"\"\n",
    "    Gathers details of the Tiny ImageNet training set.\n",
    "    Returns:\n",
    "        - sample_details: List of dicts, each {'path': str, 'original_label_idx': int, 'original_dataset_idx': int, 'wnid': str}\n",
    "        - wnid_to_idx: Dict mapping WNID to original integer label (0-199)\n",
    "        - idx_to_wnid: Dict mapping original integer label to WNID\n",
    "        - all_wnids_ordered: List of WNIDs, order defines the 0-199 mapping\n",
    "    \"\"\"\n",
    "    train_dir = os.path.join(dataset_path, 'train')\n",
    "    wnids_file = os.path.join(dataset_path, 'wnids.txt')\n",
    "\n",
    "    with open(wnids_file, 'r') as f:\n",
    "        all_wnids_ordered = [line.strip() for line in f]\n",
    "\n",
    "    wnid_to_idx = {wnid: i for i, wnid in enumerate(all_wnids_ordered)} # Maps WNID to original integer label (0-199)\n",
    "    idx_to_wnid = {i: wnid for wnid, i in wnid_to_idx.items()} # Maps original integer label to WNID\n",
    "\n",
    "    sample_details = []\n",
    "    current_original_idx = 0\n",
    "    logging.info(\"Scanning Tiny ImageNet training directory...\")\n",
    "\n",
    "    # Retrieve all image paths for each class\n",
    "    for wnid in os.listdir(train_dir):\n",
    "        if wnid not in wnid_to_idx:\n",
    "            continue # Skip non-class folders like .DS_Store\n",
    "\n",
    "        original_class_idx = wnid_to_idx[wnid]\n",
    "        class_image_dir = os.path.join(train_dir, wnid, 'images')\n",
    "\n",
    "        # Check if 'images' subdirectory exists, if not, check current wnid directory\n",
    "        if not os.path.isdir(class_image_dir):\n",
    "             img_files_dir = os.path.join(train_dir, wnid)\n",
    "        else:\n",
    "            img_files_dir = class_image_dir\n",
    "\n",
    "        for img_name in os.listdir(img_files_dir):\n",
    "            if img_name.lower().endswith(('.jpeg', '.jpg', '.png')):\n",
    "                img_path = os.path.join(img_files_dir, img_name)\n",
    "                sample_details.append({\n",
    "                    'path': img_path,\n",
    "                    'original_label_idx': original_class_idx,\n",
    "                    'original_dataset_idx': current_original_idx,\n",
    "                    'wnid': wnid\n",
    "                })\n",
    "                current_original_idx += 1\n",
    "\n",
    "    if not sample_details:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No images found. Please check the structure of {train_dir}. \"\n",
    "            f\"Expected structure: {train_dir}/<wnid>/images/<image_file.JPEG> or {train_dir}/<wnid>/<image_file.JPEG>\"\n",
    "        )\n",
    "\n",
    "    logging.info(f\"Found {len(sample_details)} training images from {len(all_wnids_ordered)} classes.\")\n",
    "    return sample_details, wnid_to_idx, idx_to_wnid, all_wnids_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Split classes into In-Distribution (ID) and Out-of-Distribution (OOD)\n",
    "tiny_imagenet_dir = os.path.join(DATA_DIR, 'tiny-imagenet-200')\n",
    "\n",
    "if not os.path.exists(tiny_imagenet_dir):\n",
    "    logging.info(f\"Error: Tiny ImageNet directory not found at '{tiny_imagenet_dir}'.\")\n",
    "    logging.info(f\"Please download and extract Tiny ImageNet to the {DATA_DIR}.\")\n",
    "    raise FileNotFoundError(f\"Tiny ImageNet directory not found at '{tiny_imagenet_dir}'\")\n",
    "\n",
    "sample_details, wnid_to_idx, idx_to_wnid, all_wnids_ordered = \\\n",
    "    get_tiny_imagenet_train_data_details(tiny_imagenet_dir)\n",
    "\n",
    "num_total_original_classes = len(all_wnids_ordered) # Should be 200\n",
    "\n",
    "# 1. Split classes into In-Distribution (ID) and Out-of-Distribution (OOD)\n",
    "all_original_class_indices = list(range(num_total_original_classes))\n",
    "random.shuffle(all_original_class_indices)\n",
    "\n",
    "num_id_classes = int(IND_CLASS_RATIO * num_total_original_classes) # Should be 160\n",
    "\n",
    "pretrain_classes_original_idxs = sorted(all_original_class_indices[:num_id_classes])\n",
    "ood_classes_original_idxs = sorted(all_original_class_indices[num_id_classes:])\n",
    "\n",
    "logging.info(f\"\\nTotal classes: {num_total_original_classes}\")\n",
    "logging.info(f\"In-distribution (ID) classes selected (original indices): {len(pretrain_classes_original_idxs)}\")\n",
    "logging.info(f\"Out-of-distribution (OOD) classes selected (original indices): {len(ood_classes_original_idxs)}\")\n",
    "\n",
    "# 2. Create mapping for ID classes to new contiguous labels [0, num_id_classes-1]\n",
    "ind_class_mapping_from_original = {\n",
    "    original_idx: new_idx for new_idx, original_idx in enumerate(pretrain_classes_original_idxs)\n",
    "}\n",
    "\n",
    "# 3. Group samples by their original class\n",
    "samples_by_original_class = defaultdict(list)\n",
    "for sample in sample_details:\n",
    "    samples_by_original_class[sample['original_label_idx']].append(sample)\n",
    "\n",
    "pretrained_ind_indices = []      # List of original_dataset_idx for ViT training (75% of ID)\n",
    "pretrained_left_out_indices = [] # List of original_dataset_idx for ID data not used in ViT training (25% of ID)\n",
    "\n",
    "logging.info(\"\\nSplitting samples for ID classes:\")\n",
    "for original_class_idx in pretrain_classes_original_idxs:\n",
    "    class_samples = samples_by_original_class[original_class_idx]\n",
    "    random.shuffle(class_samples) # Shuffle samples within the class\n",
    "\n",
    "    num_samples_in_class = len(class_samples)\n",
    "    num_for_pretrain = int(PRETRAIN_EXAMPLE_RATIO * num_samples_in_class)\n",
    "\n",
    "    # Ensure at least one sample for pretraining if class is not empty\n",
    "    if num_samples_in_class > 0 and num_for_pretrain == 0:\n",
    "        num_for_pretrain = 1\n",
    "\n",
    "    for i, sample in enumerate(class_samples):\n",
    "        if i < num_for_pretrain:\n",
    "            pretrained_ind_indices.append(sample['original_dataset_idx'])\n",
    "        else:\n",
    "            pretrained_left_out_indices.append(sample['original_dataset_idx'])\n",
    "\n",
    "pretrained_ind_indices.sort()\n",
    "pretrained_left_out_indices.sort()\n",
    "\n",
    "logging.info(f\"Total samples for ViT pretraining (75% of ID): {len(pretrained_ind_indices)}\")\n",
    "logging.info(f\"Total ID samples left out from pretraining (25% of ID): {len(pretrained_left_out_indices)}\")\n",
    "\n",
    "# Store class information\n",
    "class_info = {\n",
    "    'num_of_classes': num_total_original_classes,\n",
    "    'pretrain_classes': pretrain_classes_original_idxs, # List of original class indices (0-199) for ID\n",
    "    'left_out_classes': ood_classes_original_idxs,   # List of original class indices (0-199) for OOD\n",
    "    'left_out_ind_indices': pretrained_left_out_indices,\n",
    "    'pretrained_ind_indices': pretrained_ind_indices,\n",
    "    'pretrain_class_mapping': ind_class_mapping_from_original, # Maps original ID class_idx -> new contiguous idx\n",
    "    'wnid_to_idx': wnid_to_idx, # wnid -> original_idx (0-199)\n",
    "    'idx_to_wnid': idx_to_wnid, # original_idx (0-199) -> wnid\n",
    "    'all_wnids_ordered': all_wnids_ordered # Defines the 0-199 mapping\n",
    "}\n",
    "\n",
    "# Save all image paths and their original labels for easy access in the training script\n",
    "# This avoids re-scanning the directory in the training script.\n",
    "all_training_image_paths = [s['path'] for s in sample_details]\n",
    "all_training_original_labels = [s['original_label_idx'] for s in sample_details]\n",
    "\n",
    "data_to_save = {\n",
    "    'class_info': class_info,\n",
    "    'all_training_image_paths': all_training_image_paths,\n",
    "    'all_training_original_labels': all_training_original_labels\n",
    "}\n",
    "\n",
    "save_file = os.path.join(SAVE_DIR, 'tiny_imagenet_data_info.pth')\n",
    "torch.save(data_to_save, save_file)\n",
    "logging.info(f\"\\nPreprocessing complete. Data information saved to: {save_file}\")\n",
    "\n",
    "# For convenience, also save just the class_info as requested by user for OOD experiments\n",
    "class_info_only_file = os.path.join(SAVE_DIR, 'class_info.pth')\n",
    "torch.save(class_info, class_info_only_file)\n",
    "logging.info(f\"Class_info (for OOD experiments) saved to: {class_info_only_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omccood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
